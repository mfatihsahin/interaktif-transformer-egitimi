<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/interaktif-transformer-egitimi/_next/static/media/92f44bb82993d879-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/interaktif-transformer-egitimi/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/interaktif-transformer-egitimi/_next/static/css/738566904f298e78.css" data-precedence="next"/><link rel="stylesheet" href="/interaktif-transformer-egitimi/_next/static/css/6503823eacba4391.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/interaktif-transformer-egitimi/_next/static/chunks/webpack-1b5bce0a74013322.js"/><script src="/interaktif-transformer-egitimi/_next/static/chunks/4bd1b696-9a8865763ff351c4.js" async=""></script><script src="/interaktif-transformer-egitimi/_next/static/chunks/684-dca4fc43083d5157.js" async=""></script><script src="/interaktif-transformer-egitimi/_next/static/chunks/main-app-b727a958e39e4a18.js" async=""></script><script src="/interaktif-transformer-egitimi/_next/static/chunks/d3ac728e-42baa62b664f1369.js" async=""></script><script src="/interaktif-transformer-egitimi/_next/static/chunks/559-913a8773b61726c1.js" async=""></script><script src="/interaktif-transformer-egitimi/_next/static/chunks/app/page-16b4deb233b3312f.js" async=""></script><meta name="next-size-adjust" content=""/><title>Transformer Architecture Explained</title><meta name="description" content="An interactive explanation of the Transformer architecture - step by step from fundamentals to advanced concepts"/><meta name="keywords" content="transformer, machine learning, deep learning, nlp, attention mechanism, neural networks"/><link rel="icon" href="/interaktif-transformer-egitimi/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/interaktif-transformer-egitimi/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_96f221 __variable_bd0191 font-sans antialiased"><div class="min-h-screen"><header class="sticky top-0 z-50 transition-all duration-300 bg-transparent"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center py-4"><div class="flex items-center"><a class="flex items-center space-x-2" href="/interaktif-transformer-egitimi"><span class="text-2xl font-bold bg-gradient-to-r from-indigo-600 to-purple-600 dark:from-indigo-400 dark:to-purple-400 text-transparent bg-clip-text">Transformer</span></a></div><nav class="hidden md:flex space-x-1"><a class="px-3 py-2 rounded-md text-sm font-medium transition-colors relative text-gray-700 hover:text-indigo-600 dark:text-gray-300 dark:hover:text-indigo-400" href="#introduction">Introduction</a><a class="px-3 py-2 rounded-md text-sm font-medium transition-colors relative text-gray-700 hover:text-indigo-600 dark:text-gray-300 dark:hover:text-indigo-400" href="#outline">Outline</a><a class="px-3 py-2 rounded-md text-sm font-medium transition-colors relative text-gray-700 hover:text-indigo-600 dark:text-gray-300 dark:hover:text-indigo-400" href="#seq-models">Sequence Models</a><a class="px-3 py-2 rounded-md text-sm font-medium transition-colors relative text-gray-700 hover:text-indigo-600 dark:text-gray-300 dark:hover:text-indigo-400" href="#attention">Attention Mechanism</a><a class="px-3 py-2 rounded-md text-sm font-medium transition-colors relative text-gray-700 hover:text-indigo-600 dark:text-gray-300 dark:hover:text-indigo-400" href="#architecture">Transformer Architecture</a><a class="px-3 py-2 rounded-md text-sm font-medium transition-colors relative text-gray-700 hover:text-indigo-600 dark:text-gray-300 dark:hover:text-indigo-400" href="#applications">Applications</a><a class="px-3 py-2 rounded-md text-sm font-medium transition-colors relative text-gray-700 hover:text-indigo-600 dark:text-gray-300 dark:hover:text-indigo-400" href="#demo">Interactive Demo</a></nav><div class="md:hidden"><button class="text-gray-700 dark:text-gray-300"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16m-7 6h7"></path></svg></button></div></div></div></header><section id="introduction" class="section-container pt-24 sm:pt-32"><div class="flex flex-col lg:flex-row items-center justify-between gap-12"><div class="lg:w-1/2"><h1 class="text-4xl sm:text-5xl font-bold mb-6" style="opacity:0;transform:translateY(20px)">Understanding the <span class="highlight">Transformer</span> Architecture</h1><p class="text-lg mb-8 text-gray-700 dark:text-gray-300" style="opacity:0;transform:translateY(20px)">A step-by-step visual journey through the architecture that revolutionized natural language processing and beyond.</p><div class="flex gap-4 mb-8" style="opacity:0;transform:translateY(20px)"><button class="px-6 py-3 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-md transition-colors">Begin Learning</button><button class="px-6 py-3 border border-gray-300 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-800 rounded-md transition-colors">Jump to Demo</button></div></div><div class="lg:w-1/2" style="opacity:0;transform:scale(0.9)"><div class="aspect-video relative bg-gradient-to-br from-indigo-500 to-purple-600 rounded-lg shadow-xl overflow-hidden"><div class="absolute inset-0 flex items-center justify-center text-white text-lg font-medium">Transformers: Attention is All You Need</div></div></div></div></section><section id="outline" class="section-container py-16 bg-gray-50 dark:bg-slate-900"><div class="max-w-4xl mx-auto"><h2 class="text-3xl font-bold mb-8 text-center">Tutorial Outline</h2><p class="text-center mb-10 text-gray-700 dark:text-gray-300">Follow this step-by-step guide to understand the Transformer architecture from fundamentals to advanced concepts.</p><div class="grid gap-6 md:grid-cols-2"><div class="card border-l-4 border-blue-500 hover:shadow-lg transition-all" style="opacity:0;transform:translateY(20px)"><h3 class="text-xl font-semibold mb-2">1. Sequence-to-Sequence Modeling</h3><p class="text-gray-600 dark:text-gray-400">Explore traditional sequence models like RNNs, LSTMs, and GRUs, their limitations, and why we needed a better architecture. Learn about the information bottleneck problem in encoder-decoder frameworks.</p><button class="mt-3 text-indigo-600 dark:text-indigo-400 font-medium hover:underline">Jump to section →</button></div><div class="card border-l-4 border-purple-500 hover:shadow-lg transition-all" style="opacity:0;transform:translateY(20px)"><h3 class="text-xl font-semibold mb-2">2. Attention Mechanism</h3><p class="text-gray-600 dark:text-gray-400">Understand how attention mechanisms allow models to focus on relevant parts of the input sequence. Visualize attention weights and see how they improve the context encoding.</p><button class="mt-3 text-indigo-600 dark:text-indigo-400 font-medium hover:underline">Jump to section →</button></div><div class="card border-l-4 border-green-500 hover:shadow-lg transition-all" style="opacity:0;transform:translateY(20px)"><h3 class="text-xl font-semibold mb-2">3. Self-Attention &amp; Multi-Head Attention</h3><p class="text-gray-600 dark:text-gray-400">Discover the key innovation of self-attention that allows each position to attend to all positions, and how multiple attention heads capture different aspects of relationships between tokens.</p><button class="mt-3 text-indigo-600 dark:text-indigo-400 font-medium hover:underline">Jump to section →</button></div><div class="card border-l-4 border-red-500 hover:shadow-lg transition-all" style="opacity:0;transform:translateY(20px)"><h3 class="text-xl font-semibold mb-2">4. Transformer Architecture</h3><p class="text-gray-600 dark:text-gray-400">Explore the complete transformer architecture with its encoder-decoder structure, positional encodings, feed-forward networks, and the powerful combination of components.</p><button class="mt-3 text-indigo-600 dark:text-indigo-400 font-medium hover:underline">Jump to section →</button></div><div class="card border-l-4 border-yellow-500 hover:shadow-lg transition-all" style="opacity:0;transform:translateY(20px)"><h3 class="text-xl font-semibold mb-2">5. Applications &amp; Variants</h3><p class="text-gray-600 dark:text-gray-400">Learn about real-world applications of transformers in NLP, computer vision, and scientific domains. Discover popular transformer variants like BERT, GPT, T5, and Vision Transformer.</p><button class="mt-3 text-indigo-600 dark:text-indigo-400 font-medium hover:underline">Jump to section →</button></div><div class="card border-l-4 border-indigo-500 hover:shadow-lg transition-all" style="opacity:0;transform:translateY(20px)"><h3 class="text-xl font-semibold mb-2">6. Interactive Demo</h3><p class="text-gray-600 dark:text-gray-400">Experience transformers in action with an interactive demo that lets you generate text and observe how the model processes your inputs to produce meaningful outputs.</p><button class="mt-3 text-indigo-600 dark:text-indigo-400 font-medium hover:underline">Jump to section →</button></div></div></div></section><section id="seq-models" class="section-container"><div class="max-w-4xl mx-auto"><h2 class="text-3xl font-bold mb-6">Sequence-to-Sequence Modeling</h2><p class="mb-6 text-gray-700 dark:text-gray-300">Sequence-to-sequence models are a class of neural networks designed to transform one sequence into another. Before the Transformer architecture, these tasks primarily relied on Recurrent Neural Networks (RNNs) and their variants. Let&#x27;s explore how these models work and the fundamental limitations that motivated the development of Transformers.</p><div class="card mb-8"><h3 class="text-xl font-semibold mb-4">What is Sequence-to-Sequence Learning?</h3><p class="mb-4 text-gray-700 dark:text-gray-300">Sequence-to-sequence (Seq2Seq) learning refers to the task of converting an input sequence into a corresponding output sequence, where the lengths of input and output may differ. Applications include:</p><div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6"><div class="p-3 bg-blue-50 dark:bg-blue-900/20 rounded-md"><h4 class="font-medium mb-2 text-blue-700 dark:text-blue-400">Machine Translation</h4><p class="text-sm">Converting text from one language to another, where grammar and word order may differ significantly.</p></div><div class="p-3 bg-purple-50 dark:bg-purple-900/20 rounded-md"><h4 class="font-medium mb-2 text-purple-700 dark:text-purple-400">Text Summarization</h4><p class="text-sm">Generating a concise summary from a longer document while preserving key information.</p></div><div class="p-3 bg-green-50 dark:bg-green-900/20 rounded-md"><h4 class="font-medium mb-2 text-green-700 dark:text-green-400">Speech Recognition</h4><p class="text-sm">Converting audio waveforms into text transcriptions.</p></div></div><p class="text-gray-700 dark:text-gray-300">The core challenge in sequence-to-sequence learning is effectively modeling complex dependencies between input and output elements, regardless of their positions in the sequences. This becomes particularly difficult when dealing with long-range dependencies in natural language.</p></div><div class="mb-12"><h3 class="text-xl font-semibold mb-4">Recurrent Neural Networks (RNNs)</h3><p class="mb-6 text-gray-700 dark:text-gray-300">RNNs were the first major architecture for sequence modeling. They process text one token at a time, maintaining an internal &quot;memory&quot; (hidden state) that gets updated at each step. This sequential nature creates fundamental limitations.</p><div class="w-full max-w-3xl mx-auto mt-8 bg-white dark:bg-slate-800 rounded-lg shadow-md p-6"><h3 class="text-lg font-semibold mb-2">RNN Sequential Processing</h3><p class="text-sm text-gray-600 dark:text-gray-400 mb-6">Watch how RNNs process tokens one by one, maintaining a hidden state that gets updated with each token.</p><div class="flex flex-wrap gap-3 mb-6"><button class="px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white rounded-md">Play</button><button class="px-4 py-2 bg-gray-200 hover:bg-gray-300 dark:bg-gray-700 dark:hover:bg-gray-600 rounded-md">Reset</button><div class="flex items-center"><label class="text-sm mr-2">Speed:</label><select class="px-2 py-1 bg-white dark:bg-slate-700 border rounded-md"><option value="2000">Slow</option><option value="1000" selected="">Normal</option><option value="500">Fast</option></select></div><div class="flex items-center"><label class="text-sm flex items-center"><input type="checkbox" class="mr-2"/>Show Vanishing Gradient</label></div></div><div class="mb-6 p-4 bg-gray-50 dark:bg-slate-700 rounded-md overflow-x-auto"><div class="flex min-w-max"><div class="px-3 py-2 m-1 rounded-md border bg-indigo-100 border-indigo-500 dark:bg-indigo-900 dark:border-indigo-400" style="opacity:0;transform:translateY(20px)">The</div><div class="px-3 py-2 m-1 rounded-md border bg-white border-gray-200 dark:bg-slate-800 dark:border-gray-700" style="opacity:0;transform:translateY(20px)">transformer</div><div class="px-3 py-2 m-1 rounded-md border bg-white border-gray-200 dark:bg-slate-800 dark:border-gray-700" style="opacity:0;transform:translateY(20px)">architecture</div><div class="px-3 py-2 m-1 rounded-md border bg-white border-gray-200 dark:bg-slate-800 dark:border-gray-700" style="opacity:0;transform:translateY(20px)">was</div><div class="px-3 py-2 m-1 rounded-md border bg-white border-gray-200 dark:bg-slate-800 dark:border-gray-700" style="opacity:0;transform:translateY(20px)">created</div><div class="px-3 py-2 m-1 rounded-md border bg-white border-gray-200 dark:bg-slate-800 dark:border-gray-700" style="opacity:0;transform:translateY(20px)">to</div><div class="px-3 py-2 m-1 rounded-md border bg-white border-gray-200 dark:bg-slate-800 dark:border-gray-700" style="opacity:0;transform:translateY(20px)">address</div><div class="px-3 py-2 m-1 rounded-md border bg-white border-gray-200 dark:bg-slate-800 dark:border-gray-700" style="opacity:0;transform:translateY(20px)">limitations</div><div class="px-3 py-2 m-1 rounded-md border bg-white border-gray-200 dark:bg-slate-800 dark:border-gray-700" style="opacity:0;transform:translateY(20px)">of</div><div class="px-3 py-2 m-1 rounded-md border bg-white border-gray-200 dark:bg-slate-800 dark:border-gray-700" style="opacity:0;transform:translateY(20px)">RNNs</div></div></div><div class="relative h-80 bg-gray-50 dark:bg-slate-700 rounded-md p-4 overflow-hidden"><div class="absolute left-1/2 transform -translate-x-1/2 top-8 w-40 h-16 rounded-lg bg-green-500 flex items-center justify-center text-white font-medium">Hidden State<span class="absolute -bottom-6 text-xs text-gray-600 dark:text-gray-400">h<sub>0</sub></span></div><div class="absolute left-8 top-40 px-4 py-2 rounded-md bg-indigo-600 text-white" style="opacity:0;transform:translateX(-50px)">Current Token: <!-- -->The</div><div class="absolute left-1/2 transform -translate-x-1/2 top-40 w-32 h-32 rounded-full border-4 border-purple-500 flex items-center justify-center bg-white dark:bg-slate-800"><div class="text-center"><div class="font-medium">RNN Cell</div><div class="text-xs mt-1 text-gray-600 dark:text-gray-400">Processing...</div></div></div><svg class="absolute inset-0 w-full h-full pointer-events-none" xmlns="http://www.w3.org/2000/svg"><path d="M 200,80 L 200,130" stroke="#10B981" stroke-width="2" fill="none" marker-end="url(#arrowhead)"></path><path d="M 220,130 L 220,80" stroke="#8B5CF6" stroke-width="2" fill="none" marker-end="url(#arrowhead)"></path><defs><marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto"><polygon points="0 0, 10 3.5, 0 7"></polygon></marker></defs></svg></div><div class="mt-6 flex flex-col items-center"><div class="text-sm mb-2">Step: <!-- -->0<!-- --> / <!-- -->10</div><div class="w-full max-w-md bg-gray-200 dark:bg-gray-700 rounded-full h-2.5 mb-4"><div class="bg-indigo-600 h-2.5 rounded-full" style="width:0%"></div></div><div class="flex gap-2 flex-wrap justify-center"><button class="w-8 h-8 rounded-full bg-indigo-600 text-white">0</button><button class="w-8 h-8 rounded-full bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">1</button><button class="w-8 h-8 rounded-full bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">2</button><button class="w-8 h-8 rounded-full bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">3</button><button class="w-8 h-8 rounded-full bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">4</button><button class="w-8 h-8 rounded-full bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">5</button><button class="w-8 h-8 rounded-full bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">6</button><button class="w-8 h-8 rounded-full bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">7</button><button class="w-8 h-8 rounded-full bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">8</button><button class="w-8 h-8 rounded-full bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">9</button><button class="w-8 h-8 rounded-full bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">10</button></div></div></div></div><div class="mb-12"><h3 class="text-xl font-semibold mb-4">Technical Evolution of Sequence Models</h3><p class="mb-6 text-gray-700 dark:text-gray-300">As researchers attempted to overcome the limitations of vanilla RNNs, several enhanced architectures were developed. Let&#x27;s compare the technical details of these models and see how they eventually led to the Transformer breakthrough.</p><div class="w-full max-w-4xl mx-auto mt-8 bg-white dark:bg-slate-800 rounded-lg shadow-md p-6"><h3 class="text-lg font-semibold mb-4">Technical Comparison: RNN Variants vs. Transformers</h3><div class="flex flex-wrap gap-2 mb-6 border-b border-gray-200 dark:border-gray-700"><button class="px-4 py-2 text-sm font-medium rounded-t-lg transition-colors bg-indigo-600 text-white">Vanilla RNN</button><button class="px-4 py-2 text-sm font-medium rounded-t-lg transition-colors bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600">LSTM (Long Short-Term Memory)</button><button class="px-4 py-2 text-sm font-medium rounded-t-lg transition-colors bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600">GRU (Gated Recurrent Unit)</button><button class="px-4 py-2 text-sm font-medium rounded-t-lg transition-colors bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600">Transformer</button></div><div class="grid grid-cols-1 lg:grid-cols-2 gap-6"><div><div class="space-y-4" style="opacity:0;transform:translateX(-20px)"><div><h4 class="text-xl font-semibold mb-1">Vanilla RNN</h4><div class="text-sm text-gray-500 dark:text-gray-400">Introduced around <!-- -->1986</div><p class="mt-2 text-gray-700 dark:text-gray-300">Basic recurrent neural network that processes sequences one token at a time, maintaining a hidden state.</p></div><div><h5 class="font-medium mb-2">Key Equation</h5><div class="bg-gray-50 dark:bg-slate-700 p-4 rounded-md overflow-x-auto"><div class="formula "></div></div></div><div class="grid grid-cols-1 sm:grid-cols-2 gap-4"><div><h5 class="font-medium mb-2 text-green-600 dark:text-green-400">Advantages</h5><ul class="list-disc pl-5 space-y-1 text-sm"><li>Simple architecture</li><li>Efficient for short sequences</li><li>Minimal parameter count</li></ul></div><div><h5 class="font-medium mb-2 text-red-600 dark:text-red-400">Limitations</h5><ul class="list-disc pl-5 space-y-1 text-sm"><li>Vanishing/exploding gradients</li><li>Difficulty capturing long-range dependencies</li><li>Sequential processing (slow)</li><li>Fixed-size hidden state</li></ul></div></div></div></div><div class="bg-gray-50 dark:bg-slate-700 p-4 rounded-lg"><h4 class="text-lg font-medium mb-4">Performance Comparison</h4><div class="mb-6"><div class="flex justify-between mb-1"><span class="text-sm font-medium">Computational Complexity</span><span class="text-sm font-medium">3<!-- -->/10</span></div><div class="w-full bg-gray-200 dark:bg-gray-600 rounded-full h-2.5"><div class="bg-blue-600 h-2.5 rounded-full" style="width:0px"></div></div><div class="text-xs text-gray-500 dark:text-gray-400 mt-1">Lower complexity but also lower performance ceiling</div></div><div class="mb-6"><div class="flex justify-between mb-1"><span class="text-sm font-medium">Parallelization Capability</span><span class="text-sm font-medium">1<!-- -->/10</span></div><div class="w-full bg-gray-200 dark:bg-gray-600 rounded-full h-2.5"><div class="bg-purple-600 h-2.5 rounded-full" style="width:0px"></div></div><div class="text-xs text-gray-500 dark:text-gray-400 mt-1">Sequential processing limits parallelization and training speed</div></div><div class="mb-6"><div class="flex justify-between mb-1"><span class="text-sm font-medium">Long-Range Dependency Modeling</span><span class="text-sm font-medium">2<!-- -->/10</span></div><div class="w-full bg-gray-200 dark:bg-gray-600 rounded-full h-2.5"><div class="bg-green-600 h-2.5 rounded-full" style="width:0px"></div></div><div class="text-xs text-gray-500 dark:text-gray-400 mt-1">Information must flow through many timesteps, weakening long-range connections</div></div><div class="mt-8"><h4 class="text-sm font-medium mb-2">Timeline of Development</h4><div class="relative h-12 bg-gray-200 dark:bg-gray-600 rounded-md"><div class="absolute bottom-0 transform -translate-x-1/2 z-10" style="left:2.857142857142857%;transform:translateY(20px)"><div class="h-4 w-4 rounded-full bg-indigo-600"></div><div class="text-xs font-medium mt-1 text-indigo-600 dark:text-indigo-400">1986</div><div class="text-[10px] whitespace-nowrap text-indigo-600 dark:text-indigo-400 font-medium">Vanilla RNN</div></div><div class="absolute bottom-0 transform -translate-x-1/2 z-0" style="left:34.285714285714285%;transform:translateY(20px)"><div class="h-4 w-4 rounded-full bg-gray-400 dark:bg-gray-500"></div><div class="text-xs font-medium mt-1 text-gray-600 dark:text-gray-400">1997</div><div class="text-[10px] whitespace-nowrap text-gray-500 dark:text-gray-400">LSTM (Long Short-Term Memory)</div></div><div class="absolute bottom-0 transform -translate-x-1/2 z-0" style="left:82.85714285714286%;transform:translateY(20px)"><div class="h-4 w-4 rounded-full bg-gray-400 dark:bg-gray-500"></div><div class="text-xs font-medium mt-1 text-gray-600 dark:text-gray-400">2014</div><div class="text-[10px] whitespace-nowrap text-gray-500 dark:text-gray-400">GRU (Gated Recurrent Unit)</div></div><div class="absolute bottom-0 transform -translate-x-1/2 z-0" style="left:91.42857142857143%;transform:translateY(20px)"><div class="h-4 w-4 rounded-full bg-gray-400 dark:bg-gray-500"></div><div class="text-xs font-medium mt-1 text-gray-600 dark:text-gray-400">2017</div><div class="text-[10px] whitespace-nowrap text-gray-500 dark:text-gray-400">Transformer</div></div></div></div></div></div></div></div><div class="card mb-8"><h3 class="text-xl font-semibold mb-4">Limitations of RNN-based Models</h3><ul class="list-disc pl-6 space-y-3 text-gray-700 dark:text-gray-300"><li><strong>Sequential Processing:</strong> RNNs process tokens one by one, making them unable to parallelize and slow for long sequences. This sequential nature means that training time scales linearly with sequence length, becoming impractical for very long sequences.</li><li><strong>Long-range Dependencies:</strong> Information from early tokens tends to get diluted as sequences get longer. For example, in the sentence &quot;The cat, which was sitting on the mat that was purchased last week from the store downtown, is brown,&quot; the connection between &quot;cat&quot; and &quot;brown&quot; becomes difficult for RNNs to maintain.</li><li><strong>Vanishing Gradients:</strong> Gradients can vanish during backpropagation through time, making it difficult to learn long-range dependencies. As the error signal propagates backward through many time steps, it tends to diminish exponentially, effectively preventing learning from distant contexts.</li><li><strong>Lack of Parallel Processing:</strong> RNNs process tokens sequentially, making them inefficient on modern GPU hardware which excels at parallel computation. This makes training on large datasets prohibitively time-consuming.</li></ul></div><div class="mb-12"><h3 class="text-xl font-semibold mb-4">The Encoder-Decoder Framework</h3><p class="mb-4 text-gray-700 dark:text-gray-300">Traditional sequence-to-sequence models used an encoder-decoder architecture. The encoder processes the entire input sequence and compresses it into a context vector. The decoder then generates the output sequence based on this context vector.</p><div class="bg-white dark:bg-slate-800 p-6 rounded-lg shadow-md"><div class="flex flex-col md:flex-row gap-4 justify-center items-center"><div class="p-4 border border-indigo-200 dark:border-indigo-800 rounded-md bg-indigo-50 dark:bg-indigo-900/30 w-full md:w-2/5"><h4 class="font-medium text-center mb-2">Encoder</h4><p class="text-sm text-center text-gray-600 dark:text-gray-400">Processes the input sequence and compresses it into a context vector</p></div><div class="text-center text-gray-400">→</div><div class="w-full md:w-1/5 py-2 text-center"><div class="bg-gray-200 dark:bg-gray-700 p-2 rounded-md mx-auto w-full max-w-[100px]"><p class="text-xs">Context Vector</p></div></div><div class="text-center text-gray-400">→</div><div class="p-4 border border-purple-200 dark:border-purple-800 rounded-md bg-purple-50 dark:bg-purple-900/30 w-full md:w-2/5"><h4 class="font-medium text-center mb-2">Decoder</h4><p class="text-sm text-center text-gray-600 dark:text-gray-400">Generates the output sequence token by token based on the context</p></div></div></div></div><div class="mb-12"><h3 class="text-xl font-semibold mb-4">The Information Bottleneck Problem</h3><p class="mb-6 text-gray-700 dark:text-gray-300">A critical limitation of the encoder-decoder framework was the bottleneck created by compressing all information into a fixed-size context vector. This bottleneck became particularly problematic for long sequences where important information could be lost.</p><div class="w-full max-w-3xl mx-auto mt-8 bg-white dark:bg-slate-800 rounded-lg shadow-md p-6"><h3 class="text-lg font-semibold mb-2">The Information Bottleneck Problem</h3><p class="text-sm text-gray-600 dark:text-gray-400 mb-6">See how traditional encoder-decoder models compress all input information into a fixed-size context vector, creating a bottleneck that loses information, especially with longer sequences.</p><div class="flex flex-wrap gap-3 mb-6"><button class="px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white rounded-md">Use Long Sequence</button><label class="inline-flex items-center"><input type="checkbox" class="mr-2"/><span class="text-sm">Show Information Loss</span></label></div><div class="relative h-96 bg-gray-50 dark:bg-slate-700 rounded-md p-4 overflow-hidden"><div class="absolute top-4 left-4 w-1/2 pr-4"><div class="text-sm font-medium mb-2">Source Sentence (Input)</div><div class="flex flex-wrap gap-1"><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">The</div><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">quick</div><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">brown</div><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">fox</div><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">jumps</div><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">over</div></div></div><div class="absolute top-4 right-4 w-1/2 pl-4 text-right"><div class="text-sm font-medium mb-2">Target Sentence (Output)</div><div class="flex flex-wrap gap-1 justify-end"><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">Der</div><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">schnelle</div><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">braune</div><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">Fuchs</div><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">springt</div><div class="px-2 py-1 text-sm rounded-md bg-white dark:bg-slate-800 border border-gray-300 dark:border-gray-700" style="opacity:0">über</div></div></div><div class="absolute top-1/3 left-1/4 transform -translate-x-1/2 -translate-y-1/2 w-32 h-32 bg-blue-500 dark:bg-blue-700 rounded-lg flex items-center justify-center text-white font-medium">Encoder</div><div class="absolute top-1/3 right-1/4 transform translate-x-1/2 -translate-y-1/2 w-32 h-32 bg-purple-500 dark:bg-purple-700 rounded-lg flex items-center justify-center text-white font-medium">Decoder</div><div class="absolute top-1/3 left-1/2 transform -translate-x-1/2 -translate-y-1/2 w-20 h-20 bg-green-500 dark:bg-green-700 rounded-full flex items-center justify-center text-white text-sm text-center" style="transform:scale(0)">Context Vector</div><svg class="absolute inset-0 w-full h-full pointer-events-none" xmlns="http://www.w3.org/2000/svg"><path d="M 110,120 L 190,120" stroke="#D1D5DB" stroke-width="3" stroke-dasharray="5,5" fill="none" marker-end="url(#arrowhead)"></path><path d="M 210,120 L 290,120" stroke="#D1D5DB" stroke-width="3" stroke-dasharray="5,5" fill="none" marker-end="url(#arrowhead)"></path><defs><marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto"><polygon points="0 0, 10 3.5, 0 7" fill="#D1D5DB"></polygon></marker></defs></svg></div><div class="mt-6 flex justify-between items-center"><button class="px-4 py-2 bg-gray-200 hover:bg-gray-300 dark:bg-gray-700 dark:hover:bg-gray-600 rounded-md" disabled="">Reset</button><div class="text-sm">Stage: <!-- -->0<!-- --> / 3</div><button class="px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white rounded-md">Next Stage</button></div></div></div><div class="card p-5 border-l-4 border-indigo-500"><h3 class="text-xl font-semibold mb-2">Motivating the Transformer Architecture</h3><p class="text-gray-700 dark:text-gray-300 mb-4">The key problems that motivated the development of the Transformer architecture can be summarized as:</p><ol class="list-decimal pl-6 space-y-2 text-gray-700 dark:text-gray-300"><li><strong>Sequential bottlenecks</strong> in RNNs that prevented parallelization</li><li><strong>Vanishing signal</strong> across long sequences that made learning long-range dependencies difficult</li><li><strong>Information compression</strong> into a fixed-size context vector that created an information bottleneck</li><li><strong>High computational cost</strong> of training RNN models, especially for long sequences</li></ol><p class="mt-4 text-gray-700 dark:text-gray-300">The Transformer architecture, introduced in the paper &quot;Attention is All You Need&quot; (Vaswani et al., 2017), addressed all these limitations by replacing recurrence entirely with attention mechanisms. The key insight was that direct connections between all positions in a sequence could eliminate sequential processing while better capturing long-range dependencies.</p></div></div></section><section id="attention" class="section-container bg-gray-50 dark:bg-slate-900"><div class="max-w-4xl mx-auto"><h2 class="text-3xl font-bold mb-6">The Attention Mechanism</h2><p class="mb-6 text-gray-700 dark:text-gray-300">Attention mechanisms were introduced to address the bottleneck problem by allowing the decoder to &quot;look back&quot; at the source sequence. Instead of relying solely on a fixed context vector, the decoder could focus on relevant parts of the input for each output token.</p><div class="card mb-8"><h3 class="text-xl font-semibold mb-4">How Attention Works</h3><p class="mb-4 text-gray-700 dark:text-gray-300">The attention mechanism computes a weighted sum of all encoder hidden states, with weights determined by their relevance to the current decoder state.</p><div class="formula mb-6"><p class="text-center mb-2">The attention score between query q and key k:</p><div class="formula "></div><p class="text-center mb-2 mt-4">The attention weights after softmax:</p><div class="formula "></div></div><p class="text-gray-700 dark:text-gray-300">Where:</p><ul class="list-disc pl-6 space-y-1 text-gray-700 dark:text-gray-300 mt-2"><li><strong>Q</strong> (Query): What we&#x27;re looking for</li><li><strong>K</strong> (Key): What we match against</li><li><strong>V</strong> (Value): What we retrieve</li><li><strong>d<sub>k</sub></strong>: Dimensionality of the keys</li></ul></div><div class="w-full max-w-2xl mx-auto mt-8 bg-white dark:bg-slate-800 rounded-lg shadow-md p-6"><h3 class="text-lg font-semibold mb-4">Attention Visualization</h3><div class="flex flex-wrap gap-2 mb-8"><div class="px-3 py-1.5 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">The</div><div class="px-3 py-1.5 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">transformer</div><div class="px-3 py-1.5 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">model</div><div class="px-3 py-1.5 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">revolutionized</div><div class="px-3 py-1.5 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">natural</div><div class="px-3 py-1.5 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">language</div><div class="px-3 py-1.5 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">processing</div></div><div class="flex flex-wrap gap-2"><div class="px-3 py-1.5 rounded-md border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(-20px)">Das</div><div class="px-3 py-1.5 rounded-md border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(-20px)">Transformer</div><div class="px-3 py-1.5 rounded-md border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(-20px)">Modell</div><div class="px-3 py-1.5 rounded-md border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(-20px)">revolutionierte</div><div class="px-3 py-1.5 rounded-md border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(-20px)">die</div><div class="px-3 py-1.5 rounded-md border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(-20px)">Verarbeitung</div><div class="px-3 py-1.5 rounded-md border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(-20px)">natürlicher</div><div class="px-3 py-1.5 rounded-md border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(-20px)">Sprache</div></div><p class="text-sm text-gray-600 dark:text-gray-400 mt-6">Hover over the source tokens (English) to see how they attend to the target tokens (German). The intensity of the connection represents the attention weight.</p></div></div></section><section class="section-container"><div class="max-w-4xl mx-auto"><h3 class="text-2xl font-bold mb-6">Self-Attention: The Key Innovation</h3><p class="mb-6 text-gray-700 dark:text-gray-300">The transformer architecture introduces <strong>self-attention</strong>, where all queries, keys, and values come from the same sequence. This allows each token to attend to all positions in the sequence, facilitating the modeling of complex dependencies regardless of their distance.</p><div class="w-full max-w-3xl mx-auto mt-8 bg-white dark:bg-slate-800 rounded-lg shadow-md p-6"><h3 class="text-lg font-semibold mb-6">Self-Attention Visualization</h3><div class="flex flex-col items-center"><p class="text-sm text-gray-600 dark:text-gray-400 mb-4">Hover over a token to see how it attends to other tokens in the sequence.</p><div class="relative w-full py-10"><div class="flex justify-center flex-wrap gap-2 mb-4"><div class="px-3 py-2 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">The</div><div class="px-3 py-2 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">transformer</div><div class="px-3 py-2 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">architecture</div><div class="px-3 py-2 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">uses</div><div class="px-3 py-2 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">self-attention</div><div class="px-3 py-2 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">to</div><div class="px-3 py-2 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">process</div><div class="px-3 py-2 rounded-md cursor-pointer border transition-all bg-gray-100 border-gray-300 dark:bg-gray-700 dark:border-gray-600" style="opacity:0;transform:translateY(20px)">sequences</div></div></div></div></div><div class="mt-12"><h3 class="text-2xl font-bold mb-6">Multi-Head Attention</h3><p class="mb-6 text-gray-700 dark:text-gray-300">Rather than performing a single attention function, the transformer uses multiple attention heads in parallel. This allows the model to jointly attend to information from different representation subspaces at different positions.</p><div class="formula mb-8"><div class="formula "></div><div class="formula "></div></div><div class="w-full max-w-3xl mx-auto mt-8 bg-white dark:bg-slate-800 rounded-lg shadow-md p-6"><h3 class="text-lg font-semibold mb-4">Multi-Head Attention</h3><p class="text-sm text-gray-600 dark:text-gray-400 mb-6">Click on an attention head to see what it focuses on in the input sequence. Each head specializes in different aspects of the input.</p><div class="flex justify-center gap-4 mb-8"><button class="w-16 h-16 rounded-full flex items-center justify-center text-white font-medium transition-transform " tabindex="0" style="background-color:rgb(239, 68, 68);box-shadow:0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);transform:translateY(20px);opacity:0">Head <!-- -->1</button><button class="w-16 h-16 rounded-full flex items-center justify-center text-white font-medium transition-transform " tabindex="0" style="background-color:rgb(16, 185, 129);box-shadow:0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);transform:translateY(20px);opacity:0">Head <!-- -->2</button><button class="w-16 h-16 rounded-full flex items-center justify-center text-white font-medium transition-transform " tabindex="0" style="background-color:rgb(59, 130, 246);box-shadow:0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);transform:translateY(20px);opacity:0">Head <!-- -->3</button><button class="w-16 h-16 rounded-full flex items-center justify-center text-white font-medium transition-transform " tabindex="0" style="background-color:rgb(139, 92, 246);box-shadow:0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);transform:translateY(20px);opacity:0">Head <!-- -->4</button></div><div class="mb-8"><h4 class="text-sm font-medium mb-2">Input Sequence</h4><div class="flex flex-wrap gap-2 p-4 bg-gray-50 dark:bg-slate-700 rounded-md"><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">The</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">multi-head</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">attention</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">allows</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">the</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">model</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">to</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">focus</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">on</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">different</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">positions</div><div class="px-3 py-1.5 rounded-md border 
                
                bg-white dark:bg-slate-600 border-gray-200 dark:border-gray-500" style="opacity:0">simultaneously</div></div></div><div><h4 class="text-sm font-medium mb-2">What Each Head Focuses On</h4><div class="grid grid-cols-1 md:grid-cols-2 gap-4"><div class="p-4 rounded-md border transition-all border-gray-200 dark:border-gray-700" style="color:rgb(239, 68, 68);opacity:0;transform:scale(0.95)"><h5 class="font-medium mb-1">Head <!-- -->1</h5><p class="text-sm text-gray-600 dark:text-gray-400">Focuses on subject-verb relationships</p></div><div class="p-4 rounded-md border transition-all border-gray-200 dark:border-gray-700" style="color:rgb(16, 185, 129);opacity:0;transform:scale(0.95)"><h5 class="font-medium mb-1">Head <!-- -->2</h5><p class="text-sm text-gray-600 dark:text-gray-400">Attends to adjacent tokens and local context</p></div><div class="p-4 rounded-md border transition-all border-gray-200 dark:border-gray-700" style="color:rgb(59, 130, 246);opacity:0;transform:scale(0.95)"><h5 class="font-medium mb-1">Head <!-- -->3</h5><p class="text-sm text-gray-600 dark:text-gray-400">Focuses on semantic relationships between entities</p></div><div class="p-4 rounded-md border transition-all border-gray-200 dark:border-gray-700" style="color:rgb(139, 92, 246);opacity:0;transform:scale(0.95)"><h5 class="font-medium mb-1">Head <!-- -->4</h5><p class="text-sm text-gray-600 dark:text-gray-400">Looks at long-range dependencies in the sentence</p></div></div></div></div></div></div></section><section id="architecture" class="section-container bg-gray-50 dark:bg-slate-900"><div class="max-w-4xl mx-auto"><h2 class="text-3xl font-bold mb-6">The Transformer Architecture</h2><p class="mb-6 text-gray-700 dark:text-gray-300">The complete transformer architecture consists of an encoder and decoder, each composed of multiple identical layers. The key innovation is replacing recurrence entirely with attention mechanisms and feed-forward networks.</p><div class="card mb-8"><h3 class="text-xl font-semibold mb-4">Key Components</h3><div class="space-y-6"><div><h4 class="font-medium mb-2">1. Input Embedding</h4><p class="text-gray-700 dark:text-gray-300">Converts input tokens into dense vector representations of dimension d<sub>model</sub>.</p></div><div><h4 class="font-medium mb-2">2. Positional Encoding</h4><p class="text-gray-700 dark:text-gray-300 mb-3">Since the transformer doesn&#x27;t use recurrence or convolution, it has no inherent notion of token order. Positional encodings are added to the embeddings to inject information about the position of tokens in the sequence.</p><div class="formula"><div class="formula "></div><div class="formula "></div></div></div><div><h4 class="font-medium mb-2">3. Multi-Head Attention</h4><p class="text-gray-700 dark:text-gray-300">The transformer uses three types of attention:</p><ul class="list-disc pl-6 space-y-1 text-gray-700 dark:text-gray-300 mt-2"><li><strong>Encoder Self-Attention:</strong> Each encoder token attends to all encoder tokens</li><li><strong>Masked Decoder Self-Attention:</strong> Each decoder token attends to all previous decoder tokens</li><li><strong>Encoder-Decoder Attention:</strong> Each decoder token attends to all encoder tokens</li></ul></div><div><h4 class="font-medium mb-2">4. Feed-Forward Networks</h4><p class="text-gray-700 dark:text-gray-300 mb-3">Each layer in both encoder and decoder contains a fully connected feed-forward network applied to each position separately and identically.</p><div class="formula"><div class="formula "></div></div></div><div><h4 class="font-medium mb-2">5. Residual Connections and Layer Normalization</h4><p class="text-gray-700 dark:text-gray-300">Each sub-layer (attention and feed-forward) is wrapped with a residual connection followed by layer normalization:</p><div class="formula mt-3"><div class="formula "></div></div></div></div></div><div class="mb-8"><h3 class="text-xl font-semibold mb-4">Transformer Architecture Visualization</h3><p class="mb-4 text-gray-700 dark:text-gray-300">Explore the transformer architecture step by step using the interactive visualization below:</p><div class="bg-white dark:bg-slate-800 p-6 rounded-lg shadow-md"><div class="flex items-center justify-between mb-4"><button disabled="" class="px-3 py-1 rounded-md bg-gray-200 text-gray-500 cursor-not-allowed dark:bg-gray-700">Previous</button><span class="text-sm">Step <!-- -->1<!-- --> of 7</span><button class="px-3 py-1 rounded-md bg-indigo-100 hover:bg-indigo-200 text-indigo-800 dark:bg-indigo-900 dark:hover:bg-indigo-800 dark:text-indigo-200">Next</button></div><div class="w-full max-w-2xl mx-auto mt-8 mb-12"><div class="relative h-[500px] w-full bg-white dark:bg-slate-900 rounded-lg shadow-md overflow-hidden p-6"><div class="flex flex-col h-full justify-between"><div class="p-3 rounded-lg shadow-sm bg-blue-500 text-white relative mb-2" style="opacity:0;transform:translateX(-50px)"><h4 class="font-medium">Input Embedding</h4><p class="text-sm mt-1" style="opacity:0">Converts input tokens to vector representations</p><div class="absolute left-1/2 bottom-0 w-0.5 bg-gray-300 dark:bg-gray-700 -mb-2 transform -translate-x-1/2 z-0 origin-top" style="height:20px;transform:scaleY(0)"></div></div><div class="p-3 rounded-lg shadow-sm bg-blue-700 text-white relative mb-2" style="opacity:0;transform:translateX(-50px)"><h4 class="font-medium">Positional Encoding</h4><div class="absolute left-1/2 bottom-0 w-0.5 bg-gray-300 dark:bg-gray-700 -mb-2 transform -translate-x-1/2 z-0 origin-top" style="height:20px;transform:scaleY(0)"></div></div><div class="p-3 rounded-lg shadow-sm bg-purple-600 text-white relative mb-2" style="opacity:0;transform:translateX(-50px)"><h4 class="font-medium">Multi-Head Attention</h4><div class="absolute left-1/2 bottom-0 w-0.5 bg-gray-300 dark:bg-gray-700 -mb-2 transform -translate-x-1/2 z-0 origin-top" style="height:20px;transform:scaleY(0)"></div></div><div class="p-3 rounded-lg shadow-sm bg-gray-500 text-white relative mb-2" style="opacity:0;transform:translateX(-50px)"><h4 class="font-medium">Add &amp; Normalize</h4><div class="absolute left-1/2 bottom-0 w-0.5 bg-gray-300 dark:bg-gray-700 -mb-2 transform -translate-x-1/2 z-0 origin-top" style="height:20px;transform:scaleY(0)"></div></div><div class="p-3 rounded-lg shadow-sm bg-green-600 text-white relative mb-2" style="opacity:0;transform:translateX(-50px)"><h4 class="font-medium">Feed Forward Network</h4><div class="absolute left-1/2 bottom-0 w-0.5 bg-gray-300 dark:bg-gray-700 -mb-2 transform -translate-x-1/2 z-0 origin-top" style="height:20px;transform:scaleY(0)"></div></div><div class="p-3 rounded-lg shadow-sm bg-gray-500 text-white relative mb-2" style="opacity:0;transform:translateX(-50px)"><h4 class="font-medium">Add &amp; Normalize</h4><div class="absolute left-1/2 bottom-0 w-0.5 bg-gray-300 dark:bg-gray-700 -mb-2 transform -translate-x-1/2 z-0 origin-top" style="height:20px;transform:scaleY(0)"></div></div><div class="p-3 rounded-lg shadow-sm bg-red-600 text-white relative mb-2" style="opacity:0;transform:translateX(-50px)"><h4 class="font-medium">Output Linear &amp; Softmax</h4></div></div><div class="absolute top-0 left-0 w-full h-full pointer-events-none" style="opacity:0.7"></div></div></div></div></div><div class="card"><h3 class="text-xl font-semibold mb-4">Advantages Over Previous Architectures</h3><ul class="list-disc pl-6 space-y-2 text-gray-700 dark:text-gray-300"><li><strong>Parallelization:</strong> Unlike RNNs, transformers can process all tokens in parallel, greatly speeding up training.</li><li><strong>Long-range Dependencies:</strong> The attention mechanism allows for direct connections between any two positions, making it easier to learn long-range dependencies.</li><li><strong>No Information Bottleneck:</strong> Information flows directly between all positions without being compressed into a fixed-size context vector.</li><li><strong>Better Gradient Flow:</strong> With direct connections between positions and residual connections throughout the network, gradients flow more easily during training.</li></ul></div></div></section><section id="applications" class="section-container"><div class="max-w-4xl mx-auto"><h2 class="text-3xl font-bold mb-6">Applications of Transformers</h2><p class="mb-8 text-gray-700 dark:text-gray-300">The transformer architecture has revolutionized natural language processing and beyond, enabling breakthroughs in numerous domains.</p><div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-12"><div class="card"><h3 class="text-xl font-semibold mb-3">Natural Language Processing</h3><ul class="list-disc pl-6 space-y-1 text-gray-700 dark:text-gray-300"><li>Machine Translation</li><li>Text Summarization</li><li>Question Answering</li><li>Text Generation</li><li>Sentiment Analysis</li></ul></div><div class="card"><h3 class="text-xl font-semibold mb-3">Computer Vision</h3><ul class="list-disc pl-6 space-y-1 text-gray-700 dark:text-gray-300"><li>Image Classification</li><li>Object Detection</li><li>Image Segmentation</li><li>Image Generation</li><li>Video Understanding</li></ul></div><div class="card"><h3 class="text-xl font-semibold mb-3">Multimodal Learning</h3><ul class="list-disc pl-6 space-y-1 text-gray-700 dark:text-gray-300"><li>Image Captioning</li><li>Visual Question Answering</li><li>Text-to-Image Generation</li><li>Audio-Text Understanding</li></ul></div><div class="card"><h3 class="text-xl font-semibold mb-3">Scientific Applications</h3><ul class="list-disc pl-6 space-y-1 text-gray-700 dark:text-gray-300"><li>Protein Structure Prediction</li><li>Drug Discovery</li><li>Weather Forecasting</li><li>Chemical Reaction Prediction</li></ul></div></div><div class="card"><h3 class="text-xl font-semibold mb-4">Famous Transformer Models</h3><div class="space-y-4"><div><h4 class="font-medium">BERT (Bidirectional Encoder Representations from Transformers)</h4><p class="text-sm text-gray-700 dark:text-gray-300">Uses only the encoder portion of the transformer to create powerful contextual word embeddings.</p></div><div><h4 class="font-medium">GPT (Generative Pre-trained Transformer)</h4><p class="text-sm text-gray-700 dark:text-gray-300">Uses the decoder portion of the transformer for powerful autoregressive text generation.</p></div><div><h4 class="font-medium">T5 (Text-to-Text Transfer Transformer)</h4><p class="text-sm text-gray-700 dark:text-gray-300">Frames all NLP tasks as text-to-text problems, using the complete encoder-decoder transformer.</p></div><div><h4 class="font-medium">Vision Transformer (ViT)</h4><p class="text-sm text-gray-700 dark:text-gray-300">Adapts the transformer for image classification by treating image patches as tokens.</p></div></div></div></div></section><section id="demo" class="section-container bg-gray-50 dark:bg-slate-900"><div class="max-w-4xl mx-auto"><h2 class="text-3xl font-bold mb-6">Interactive Transformer Demo</h2><p class="mb-8 text-gray-700 dark:text-gray-300">Experience the transformer in action with this interactive demo. Select a prompt and see how the model generates completions.</p><div class="w-full max-w-3xl mx-auto mt-8 bg-white dark:bg-slate-800 rounded-lg shadow-md p-6"><h3 class="text-lg font-semibold mb-4">Interactive Transformer Demo</h3><div class="space-y-6"><div><label for="prompt" class="block text-sm font-medium mb-2">Select a prompt:</label><select id="prompt" class="w-full p-2 border rounded-md bg-white dark:bg-slate-700 border-gray-300 dark:border-gray-600"><option value="The transformer architecture is" selected="">The transformer architecture is</option><option value="Natural language processing has">Natural language processing has</option><option value="Deep learning models can">Deep learning models can</option><option value="Attention mechanisms allow">Attention mechanisms allow</option></select></div><div><button class="px-4 py-2 rounded-md text-white font-medium bg-indigo-600 hover:bg-indigo-700 dark:bg-indigo-500 dark:hover:bg-indigo-600">Generate Completions</button></div></div></div></div></section><footer class="mt-16 py-8 bg-white dark:bg-slate-800 border-t border-gray-200 dark:border-gray-700"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex flex-col md:flex-row justify-between items-center"><div class="mb-4 md:mb-0"><h3 class="text-lg font-semibold mb-2">Transformer Architecture Explained</h3><p class="text-sm text-gray-600 dark:text-gray-400">An interactive visual journey through the transformer architecture</p></div><div class="flex flex-col items-center md:items-end"><p class="text-sm text-gray-600 dark:text-gray-400 mb-2">Based on the paper &quot;Attention Is All You Need&quot; by Vaswani et al.</p><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer" class="text-sm text-indigo-600 hover:text-indigo-800 dark:text-indigo-400 dark:hover:text-indigo-300">Read the original paper →</a></div></div></div></footer></div><script src="/interaktif-transformer-egitimi/_next/static/chunks/webpack-1b5bce0a74013322.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n4:I[894,[],\"ClientPageRoot\"]\n5:I[503,[\"330\",\"static/chunks/d3ac728e-42baa62b664f1369.js\",\"559\",\"static/chunks/559-913a8773b61726c1.js\",\"974\",\"static/chunks/app/page-16b4deb233b3312f.js\"],\"default\"]\n8:I[9665,[],\"OutletBoundary\"]\nb:I[9665,[],\"ViewportBoundary\"]\nd:I[9665,[],\"MetadataBoundary\"]\nf:I[6614,[],\"\"]\n:HL[\"/interaktif-transformer-egitimi/_next/static/media/92f44bb82993d879-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/interaktif-transformer-egitimi/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/interaktif-transformer-egitimi/_next/static/css/738566904f298e78.css\",\"style\"]\n:HL[\"/interaktif-transformer-egitimi/_next/static/css/6503823eacba4391.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"ZF6mKtj5IqNW6EoDd8wzR\",\"p\":\"/interaktif-transformer-egitimi\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/interaktif-transformer-egitimi/_next/static/css/738566904f298e78.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_96f221 __variable_bd0191 font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"$undefined\",[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L4\",null,{\"Component\":\"$5\",\"searchParams\":{},\"params\":{},\"promises\":[\"$@6\",\"$@7\"]}],\"$undefined\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/interaktif-transformer-egitimi/_next/static/css/6503823eacba4391.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L8\",null,{\"children\":[\"$L9\",\"$La\",null]}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"gXkmCNKoLuSeBPBIJ2eyW\",{\"children\":[[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$f\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"6:{}\n7:{}\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n9:null\n"])</script><script>self.__next_f.push([1,"a:null\ne:[[\"$\",\"title\",\"0\",{\"children\":\"Transformer Architecture Explained\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"An interactive explanation of the Transformer architecture - step by step from fundamentals to advanced concepts\"}],[\"$\",\"meta\",\"2\",{\"name\":\"keywords\",\"content\":\"transformer, machine learning, deep learning, nlp, attention mechanism, neural networks\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/interaktif-transformer-egitimi/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script></body></html>